#!/usr/bin/env perl
# $Id:$

use strict;
use warnings;
use Getopt::Long;
use Pod::Usage;
use Log::Log4perl qw(:easy);

use GTB::File qw(Open);
use NHGRI::SVanalyzer::Comp;

our %Opt;

=head1 NAME

SVbenchmark - compare two VCF files of structural variants, reporting false positive and false negative calls in the test VCF, and precision, recall, and F1 when compared to the "truth" VCF.

=head1 SYNOPSIS

  SVbenchmark --ref <reference FASTA file> --test <VCF-formatted file of test variants> --truth <VCF-formatted file of true variants>
  SVbenchmark --ref <reference FASTA file> --distance_file <distance file produced by previous run> --test <VCF-formatted file of test variants> --truth <VCF-formatted file of true variants>

=head1 DESCRIPTION

The program steps through two VCF files, a "test" file of structural variants to be evaluated and a "truth" file of structural variants which are assumed to be correct. It first writes a distance file of distance metrics between nearby pairs of test and true variants, and then writes VCF files of true positives, false positives, and false negatives, and a summary of recall, precision, and F1 to a summary file.

=cut

#------------
# Begin MAIN 
#------------

$| = 1;

my $edlib = `which edlib-aligner`;
if (!$edlib) {
    die "Running SVbenchmark requires that edlib-aligner (http://martinsosic.com/edlib/) executable be in your Linux path.\n";
}
else {
    chomp $edlib;
}

my $commandline = join " ", @ARGV;
$commandline = $0." $commandline";

process_commandline();

my $ref_fasta = $Opt{ref};
if ($ref_fasta !~ m/^\//) {
    $ref_fasta = $ENV{'PWD'}."/$ref_fasta";
}

my $ref_db = GTB::FASTA->new($ref_fasta);

my $test_vcf = $Opt{test};
my $truth_vcf = $Opt{truth};

my $test_filter = $Opt{testfilter};
my $truth_filter = $Opt{truthfilter};

my $include_bed = $Opt{'includebed'};

my $bedtools;
if ($include_bed) {
    $bedtools = `which bedtools`;
    if (!$bedtools) {
        die "Running SVbenchmark with the --includebed option requires that the bedtools (http://bedtools.readthedocs.io/en/latest/) executable be in your Linux path.\n";
    }
    else {
        chomp $bedtools;
    }
}

my $max_distance = $Opt{'maxdist'};
my $min_size = $Opt{'minsize'};
my $normshift = $Opt{'normshift'};
my $normsizediff = $Opt{'normsizediff'};
my $normdist = $Opt{'normdist'};

my $prefix = $Opt{'prefix'};
my $output_file = "$prefix.report";

# set up logging:
$Opt{'loglevel'} = ($Opt{debug}) ? $DEBUG : 
                   (($Opt{verbose}) ? $INFO : $WARN);

Log::Log4perl->easy_init( { level => $Opt{'loglevel'},
                            file => "$prefix.log" } );

WARN($commandline);

my $output_fh = Open($output_file, "w");

my $rh_distance_matrix;
if ($Opt{'distance_file'}) {
    WARN("Reading distance file $Opt{'distance_file'}\n");
    $rh_distance_matrix = read_distance_file($Opt{'distance_file'});
    WARN("Finished reading distance file $Opt{'distance_file'}\n");
}
else {
    WARN("Calculating distances and writing to file $prefix.distances\n");
    $rh_distance_matrix = calculate_distance_matrix($test_vcf, $truth_vcf, $include_bed);
    WARN("Finished calculating distances\n");
}

WARN("Calculating recall, precision");
write_fp_fn_variants($rh_distance_matrix, $test_vcf, $truth_vcf, $include_bed, $output_fh, $prefix );

WARN("Done");

#------------
# End MAIN
#------------

sub process_commandline {
    # Set defaults here
    %Opt = ( maxdist => 100000, prefix => 'benchmark', normshift => 1.0, normsizediff => 1.0, normdist => 1.0 );
    GetOptions(\%Opt, qw( ref=s test=s truth=s maxdist=i minsize=i prefix=s includebed=s distance_file=s testfilter=s truthfilter=s normshift=f normsizediff=f normdist=f nocleanup manual help+ version verbose debug)) || pod2usage(0);
    if ($Opt{manual})  { pod2usage(verbose => 2); }
    if ($Opt{help})    { pod2usage(verbose => $Opt{help}-1); }
    if ($Opt{version}) { die "SVbenchmark.pl, ", q$Revision:$, "\n"; }
    # If non-option arguments are required, uncomment next line
    pod2usage("SVbenchmark --ref <ref fasta> --test <VCF-formatted file of variants to test> --truth <VCF-formatted file of true variants>") if !($Opt{ref} && $Opt{test} && $Opt{truth});
}

sub calculate_distance_matrix {
    my $test_vcf = shift;
    my $truth_vcf = shift;
    my $bedfile = shift;

    my $distance_file = "$prefix.distances";
    my $distance_fh = Open($distance_file, "w");

    print $distance_fh "DIST\tID1\tID2\tAVGALTLENGTH\tALTLENGTHDIFF\tAVGSIZE\tSIZEDIFF\tEDITDIST\tMAXSHIFT\tPOSDIFF\tRELSHIFT\tRELSIZEDIFF\tRELDIST\n";

    my $test_command = construct_variant_command($test_vcf, $bedfile, $test_filter);
    my $test_sortedvcf_fh = Open("$test_command");

    my $truth_command = construct_variant_command($truth_vcf, $bedfile, $truth_filter);
    my $true_sortedvcf_fh = Open("$truth_command");

    my $rh_current_last_sv; # to check for sorting
    my $total_test_svs = 0;
    my $total_true_svs = 0;

    my @current_neighborhood_true_svs = ();

    my %distances = (); # hash of distance arrays for pairs of ids

    my ($current_test_id, $current_truth_id) = (1, 1);
    while (my $rh_testsv = retrieve_next_sorted_sv($test_sortedvcf_fh, $ref_db)) {
  
        if (!($rh_testsv->{id}) || ($rh_testsv->{id} eq '.') ) { # assign sequential
            $rh_testsv->{id} = "testsv_".$current_test_id;
            $current_test_id++;
        } 
        my $test_chrom = $rh_testsv->{chrom} || ''; 
        my $test_pos = $rh_testsv->{pos} || ''; 
        my $test_end = $rh_testsv->{end} || ''; 
        if ((!($test_chrom)) || (!($test_pos)) || (!($test_end))) {
            INFO("Skipping $rh_testsv->{id} with chrom $test_chrom pos $test_pos end $test_end");
            next;
        }
        $total_test_svs++;
   
        # be sure @current_neighborhood_true_svs contains only nearby true SVs by deleting if necessary: 
        while (@current_neighborhood_true_svs) {
            my $rh_first = $current_neighborhood_true_svs[0];
            if (($rh_first->{chrom} lt $test_chrom) ||
                (($rh_first->{chrom} eq $test_chrom) && ($test_pos - $rh_first->{pos} > $max_distance))) { # not needed
                shift @current_neighborhood_true_svs;
            }
            else { # first variant should be checked
                last;
            }
        }

        # add new true SVs until beyond current SV's window:

        while (1) {
            INFO("Adding to true variants in window for test variant $rh_testsv->{id}");
            my $rh_nexttruesv = retrieve_next_sorted_sv($true_sortedvcf_fh, $ref_db);
            last if (!$rh_nexttruesv);
            if (!($rh_nexttruesv->{id}) || ($rh_nexttruesv->{id} eq '.') ) { # assign sequential
                $rh_nexttruesv->{id} = "truesv_".$current_truth_id;
                $current_truth_id++;
            } 
            my $truth_chrom = $rh_nexttruesv->{chrom}; 
            my $truth_pos = $rh_nexttruesv->{pos}; 
            my $truth_end = $rh_nexttruesv->{end}; 
            next if ((!($truth_chrom)) || (!($truth_pos)) || (!($truth_end)));
            $total_true_svs++;

            push @current_neighborhood_true_svs, $rh_nexttruesv;
            last if (($test_chrom lt $rh_nexttruesv->{chrom}) ||
                    (($test_chrom eq $rh_nexttruesv->{chrom}) && ($rh_nexttruesv->{pos} - $test_pos > $max_distance)));
        }

        # now compare test SV to all true SVs in window:
   
        foreach my $rh_truesv (@current_neighborhood_true_svs) { 
            my $comp_obj = NHGRI::SVanalyzer::Comp->new(-ref_fasta => $ref_fasta, 
                                                        -sv1_info => $rh_testsv,
                                                        -sv2_info => $rh_truesv);
            my $pos_diff = abs($rh_testsv->{pos} - $rh_truesv->{pos});
            if (($rh_truesv->{chrom} eq $rh_testsv->{chrom}) && 
                  (abs($rh_testsv->{pos} - $rh_truesv->{pos}) <= $max_distance) &&
                  ($comp_obj->potential_match())) {
                my $rh_distance_metrics = $comp_obj->calc_distance('-nocleanup' => $Opt{'nocleanup'});
                if (!(defined($rh_distance_metrics->{'edit_distance'}))) {
                    WARN("Skipping comparison of $rh_truesv->{id} and $rh_testsv->{id} due to invalid coordinates.");
                    next;
                }

                my $edit_dist = $rh_distance_metrics->{'edit_distance'};
                my $max_shift = $rh_distance_metrics->{'max_shift'};
                my $altlength_diff = $rh_distance_metrics->{'altlength_diff'};
                my $altlength_avg = $rh_distance_metrics->{'altlength_avg'};
                my $size_diff = $rh_distance_metrics->{'size_diff'};
                my $size_avg = $rh_distance_metrics->{'size_avg'};
                my $shared_denominator = $rh_distance_metrics->{'shared_denominator'};
    
                # divide maximum shift by the minimum absolute size of the two variants:
                my $d1 = abs($max_shift)/$shared_denominator;
                # divide the size difference of the two indels by the average absolute size of the difference
                my $d2 = abs($size_diff)/$shared_denominator;
                # divide edit distance by the minimum alternate haplotype length:
                my $d3 = abs($edit_dist)/$shared_denominator;
                my $id1 = $rh_testsv->{id};
                my $id2 = $rh_truesv->{id};
                print $distance_fh "DIST\t$id1\t$id2\t$altlength_avg\t$altlength_diff\t$size_avg\t$size_diff\t$edit_dist\t$max_shift\t$pos_diff\t$d1\t$d2\t$d3\n";
                $distances{$id1}->{$id2} = [$pos_diff, $d1, $d2, $d3];
            }
            else {
                INFO("No potential match for $rh_testsv->{id} and $rh_truesv->{id}");
            }
        }
    }

    close $test_sortedvcf_fh;
    close $true_sortedvcf_fh;
    close $distance_fh;
    
    return {%distances};

}

sub construct_variant_command {
    my $vcf_file = shift;
    my $bedfile = shift;
    my $filterstring = shift;

    my $command = ($bedfile) ? "bedtools intersect -a $vcf_file -b $bedfile -u -wa | " :
                        (($vcf_file =~ /\.gz$/) ? "gunzip -c $vcf_file | grep -v \'#\' | " :
                        "grep -v \'#\' $vcf_file | ");

    if ($filterstring) {
        $command .= "awk -F\"\\t\" \'\$7==\"" . $filterstring . "\" {print}\' | ";
    }

    $command .= "sort -k1,1 -k2,2n | ";

    DEBUG("$command");

    return $command;
}

sub read_distance_file {
    my $distance_file = shift;

    my $dist_fh = Open("$distance_file");

    my %distances = ();
    while (<$dist_fh>) {
        if (/^DIST/) {
            chomp;
            my ($dummy, $id1, $id2, $altlength_avg, $altlength_diff, $size_avg, $size_diff, $edit_dist, $max_shift, $pos_diff, $d1, $d2, $d3) = split /\t/, $_;
            $distances{$id1}->{$id2} = [$pos_diff, $d1, $d2, $d3];
        }
    }

    close $dist_fh;
    return {%distances};
}

sub retrieve_next_sorted_sv {
    my $variant_fh = shift;
    my $ref_db = shift;

    my $next_line = <$variant_fh>;

    if (!$next_line) {
        INFO("Returning end of file");
        return $next_line;
    }
    chomp $next_line;
    if ($next_line =~ /^(\S+)\t(\d+)\t(\S+)\t(\S+)\t(\S+)\t(\S+)\t(\S+)\t(\S+)/) {
        my ($chrom, $start, $id, $ref, $alt, $info) = ($1, $2, $3, $4, $5, $8);
        $ref = uc($ref);
        $alt = uc($alt);
 
        my $reflength = length($ref);
        my $altlength = length($alt);
 
        my $end; # if we have sequence, end will be determined as last base of REF, otherwise, from END=
        if (($ref =~ /^([ATGCN]+)$/) && ($alt =~ /^([ATGCN]+)$/)) {
            INFO("Processing sequence-specific SV $id");
            $end = $start + $reflength - 1;
        }
        elsif ($info =~ /SVTYPE=BND/ || $info =~ /SVTYPE=UNK/) {
            WARN("Skipping type BND or UNK: $next_line");
            return {};
        }
        elsif (($alt eq '<DEL>') && ($info =~ /;END=(\d+);{0,1}/ || $info =~ /^END=(\d+);{0,1}/)) { # use end tag
            $end = $1;
            my $smo = $start - 1;
            $ref = uc($ref_db->seq("$chrom:$smo-$end"));
            $alt = substr($ref, 0, 1); # first character of reference
            INFO("Calculating sequence for deletion $id");
        }
        else { # don't know how to handle this
            INFO("Skipping non-ATGC ref or alt record: $next_line");
            return {};
        }

        return {'chrom' => $chrom, 'pos' => $start, 'start' => $start, 
                'end' => $end, 'id' => $id, 'ref' => $ref,
                'alt' => $alt, 'reflength' => $reflength, 
                'altlength' => $altlength};
    }
    else {
        die "Unexpected VCF line:\n$next_line";
    }
}

sub write_fp_fn_variants {
    my $rh_distances = shift;
    my $test_vcf = shift;
    my $truth_vcf = shift;
    my $bedfile = shift;
    my $output_fh = shift;
    my $prefix = shift;

    # open files for false positives and false negatives:

    my ($no_falsepositives, $no_falsenegatives, $no_truepositives,
           $no_detectedtruepositives) = (0, 0, 0, 0);
    my $rh_truepositive_truth_ids = {};

    DEBUG("Opening falsepositive file");
    my $fp_fh = Open("$prefix.falsepositives.vcf", "w");
    my $tp_comp = Open("$prefix.truepositives_comp.vcf", "w");

    # find fp's, fn's:

    my $test_command = construct_variant_command($test_vcf, $bedfile, $test_filter);
    DEBUG($test_command);

    my $test_vcf_fh = Open("$test_command");

    my ($current_test_id, $current_truth_id) = (1, 1);
    my $duplicates_warned = 1;
    while (<$test_vcf_fh>) {
        if (/^#/) { # header line--print to fp file:
            print $fp_fh $_;
            print $tp_comp $_;
        }
        else {
            my $vcf_line = $_;
            chomp;
            my @fields = split /\t/, $_;
            my $test_id = $fields[2];
            if ($test_id eq '.') {
                $test_id = "testsv_".$current_test_id;
                $current_test_id++;
            }
            my $testsize = retrieve_variant_size(@fields);
            if (!($min_size) || ($testsize > $min_size) ) { # Tested prediction
                my @matched_ids = ($rh_distances->{$test_id}) ?
                                   keys %{$rh_distances->{$test_id}} : ();
                my @true_positives = ();
                foreach my $truth_id (@matched_ids) {
                    my @matchdistances = @{$rh_distances->{$test_id}->{$truth_id}};
                    if ($matchdistances[1] <= $normshift &&
                        $matchdistances[2] <= $normsizediff &&
                        $matchdistances[3] <= $normdist) { # found a match--TP!
                        push @true_positives, $truth_id;
                        push @{$rh_truepositive_truth_ids->{$truth_id}}, $test_id;
                    }
                }
    
                my $no_tps = @true_positives;
                if (!($no_tps)) { # no match--FP!
                    print $fp_fh $vcf_line;
                    $no_falsepositives++;
                }
                elsif ($no_tps > 1) { # potential duplicates
                    my $truth_ids = join ',', @true_positives;
                    WARN("More than one match for $test_id: $truth_ids. Does your truth file have duplicates? You will get more accurate numbers if you run SVmerge on your VCF file");
                    $duplicates_warned = 1; 
                }
    
                if ($no_tps) {
                    print $tp_comp $vcf_line;
                    $no_truepositives++;
                }
            }
        }
    }
    close $fp_fh;
    close $tp_comp;
    close $test_vcf_fh;

    my $fn_fh = Open("$prefix.falsenegatives.vcf", "w");
    my $tp_base = Open("$prefix.truepositives_base.vcf", "w");

    my $truth_command = construct_variant_command($truth_vcf, $bedfile, $truth_filter);
    DEBUG($truth_command);

    my $truth_vcf_fh = Open("$truth_command");
    $duplicates_warned = 0;
    while (<$truth_vcf_fh>) {
        if (/^#/) { # header line--print to fn file:
            print $fn_fh $_;
            print $tp_base $_;
        }
        else {
            my $vcf_line = $_;
            chomp;
            my @fields = split /\t/, $_;
            my $truth_id = $fields[2];
            if ($truth_id eq '.') {
                $truth_id = "truesv_".$current_truth_id;
                $current_truth_id++;
            }
            
            my $truesize = retrieve_variant_size(@fields);

            if (!($min_size) || ($truesize >= $min_size)) { # true variant
                my @test_matches = ($rh_truepositive_truth_ids->{$truth_id}) ? 
                                  @{$rh_truepositive_truth_ids->{$truth_id}} : ();
                my $no_test_matches = @test_matches;
    
                if (!($no_test_matches)) { # missed--FN!
                    print $fn_fh $vcf_line;
                    $no_falsenegatives++;
                }
                elsif ($no_test_matches > 1) {
                    my $test_ids = join ',', @test_matches;
                    WARN("More than one match for $truth_id: $test_ids. Does your test file have duplicates? You will get more accurate numbers if you run SVmerge on your VCF file");
                    $duplicates_warned = 1;
                }

                if ($no_test_matches) {
                    $tp_base $vcf_line;
                    $no_detectedtruepositives++;
                }
            }
        }
    }
    close $fn_fh;
    close $tp_base;
    close $truth_vcf_fh;

    # print summary statistics:
    print $output_fh "RECALL:\n";
    print $output_fh "Number of detected true variants (DTP): $no_detectedtruepositives\n";
    print $output_fh "Number of undetected true variants (FN): $no_falsenegatives\n";
    my $recallval = ($no_detectedtruepositives + $no_falsenegatives) ? $no_detectedtruepositives/($no_detectedtruepositives+$no_falsenegatives) : 'NA';
    my $recall = ($recallval eq 'NA' ) ? $recallval : sprintf("%5.2f", 100*$recallval);
    print $output_fh "Recall (DTP/(DTP+FN)): $recall\%\n";
    print $output_fh "\n";
    print $output_fh "PRECISION:\n";
    print $output_fh "Number of predictions that are true (PTP): $no_truepositives\n";
    print $output_fh "Number of false positives (FP): $no_falsepositives\n";
    my $precisionval = ($no_truepositives+$no_falsepositives) ? $no_truepositives/($no_truepositives+$no_falsepositives) : 'NA';
    my $precision = ($precisionval eq 'NA' ) ? $precisionval : sprintf("%5.2f", 100*$precisionval);
    print $output_fh "Precision (PTP/(PTP+FP)): $precision\%\n";
    print $output_fh "\n";
    my $f1score = ($recallval ne 'NA' && $precisionval ne 'NA' && $recallval + $precisionval > 0) ? 2*$recallval*$precisionval/($recallval+$precisionval) : 'NA';
    print $output_fh "F1 (2*Recall*Precision/(Recall+Precision): $f1score\n";
}

sub retrieve_variant_size {
    my @vcf_fields = @_;

    my $varsize;

    if ($vcf_fields[7] =~ /SVLEN=\-{0,1}(\d+)/) { # use SVLEN tag if present
        $varsize = $1;
    }
    elsif ($vcf_fields[3] ne '.' && $vcf_fields[4] ne '.') { # use lengths of alleles
        my $reflength = length($vcf_fields[3]);
        my $altlength = length($vcf_fields[4]);
        $varsize = ($reflength > $altlength) ? $reflength - $altlength : $altlength - $reflength;
    }
    else {
        $varsize = 0;
        WARN("Unable to determine variant size for variant at $vcf_fields[0]:$vcf_fields[1]");
    }

    return $varsize;

}

__END__

=head1 OPTIONS

=over 4

=item B<--ref <path to reference FASTA file>>

The fasta file that was used as the reference for the two VCF files being
compared.

=item B<--test <path to VCF file of test variants>>

The file of variants to be compared to the variants in the truth file.

=item B<--truth <path to VCF file of true variants>>

The file of variants to which the test variants will be compared.

=item B<--maxdist <maximum distance>>

Maximum number of base pairs separating the POS values for two variants to be
compared. Variants farther than this distance apart will be considered not to
be matching.

=item B<--minsize <minimum size>>

Minimum size of a variant to be included in a benchmarking comparison. In 
calculations of recall/sensitivity, this minimum is applied to the size of the
"true" variant. In calculations of precision, this minimum is applied to the
size of the test variant.

=item B<--prefix <prefix>>

Prefix to be used in the naming of all output files. A directory name can be
included (e.g., "myresults/sampleA") so long as the directory already 
exists.

=item B<--includebed <BED file of regions to include>>

File of regions from which to include variants. Used to filter both test
and truth variants.

=item B<--testfilter <filter string>>

String specifying the value in the test VCF record's "FILTER" field in
order for a variant to be included in the comparison.

=item B<--truthfilter <filter string>>

String specifying the value in the truth VCF record's "FILTER" field in
order for a variant to be included in the comparison.

=item B<--normshift <normalized shift value>>

Maximum allowable normalized shift between matching test and true variants.

=item B<--normsizediff <normalized size difference>>

Maximum allowable normalized size difference between matching test and true variants.

=item B<--normsizedist <normalized edit distance>>

Maximum allowable normalized edit distance between matching test and true variants.

=item B<--help|--manual>

Display documentation.  One C<--help> gives a brief synopsis, C<-h -h> shows
all options, C<--manual> provides complete documentation.

=back

=head1 AUTHOR

 Nancy Hansen - nhansen@mail.nih.gov

=head1 LEGAL

This software/database is "United States Government Work" under the terms of
the United States Copyright Act.  It was written as part of the authors'
official duties for the United States Government and thus cannot be
copyrighted.  This software/database is freely available to the public for
use without a copyright notice.  Restrictions cannot be placed on its present
or future use. 

Although all reasonable efforts have been taken to ensure the accuracy and
reliability of the software and data, the National Human Genome Research
Institute (NHGRI) and the U.S. Government does not and cannot warrant the
performance or results that may be obtained by using this software or data.
NHGRI and the U.S.  Government disclaims all warranties as to performance,
merchantability or fitness for any particular purpose. 

In any work or product derived from this material, proper attribution of the
authors as the source of the software or data should be made, using "NHGRI
Genome Technology Branch" as the citation. 

=cut
